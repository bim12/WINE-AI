{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cd7bec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape entrée modèle: (1, 224, 224, 3)\n",
      "Min/max pixels : 0.0 229.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 795ms/step\n",
      "\n",
      "Softmax brut : [[1.5940997e-04 7.2604930e-04 9.9764013e-01 1.4745030e-03]]\n",
      "Somme softmax : 1.0000001\n",
      "\n",
      "Predicted label: Healthy\n",
      "Probabilités par classe :\n",
      "  Black Rot: 0.02 %\n",
      "  ESCA: 0.07 %\n",
      "  Healthy: 99.76 %\n",
      "  Leaf Blight: 0.15 %\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "MODEL_PATH = \"./Models/DL_WINE_06_TL_FT.keras\"\n",
    "TEST_IMAGE_PATH = \"./DL/Grapevine Disease Dataset Original Data/test/Healthy/0ce12a10-c6ff-494e-a927-5ddc809c707a___Mt.N.V_HL 8945.JPG\"\n",
    "\n",
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "# Classes utilisées\n",
    "CLASS_NAMES = ['Black Rot', 'ESCA', 'Healthy', 'Leaf Blight']\n",
    "\n",
    "def prepare_image(img_path):\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img = img.resize((224, 224))\n",
    "    arr = np.asarray(img, dtype=np.float32)\n",
    "    arr = preprocess_input(arr)          # Étape CRUCIALE pour EfficientNet !\n",
    "    arr = np.expand_dims(arr, axis=0)\n",
    "    return arr\n",
    "\n",
    "arr = prepare_image(TEST_IMAGE_PATH)\n",
    "print(\"\\nShape entrée modèle:\", arr.shape)\n",
    "print(\"Min/max pixels :\", arr.min(), arr.max())\n",
    "\n",
    "preds = model.predict(arr)\n",
    "print(\"\\nSoftmax brut :\", preds)\n",
    "print(\"Somme softmax :\", np.sum(preds))\n",
    "\n",
    "pred_idx = int(np.argmax(preds))\n",
    "pred_label = CLASS_NAMES[pred_idx]\n",
    "print(f\"\\nPredicted label: {pred_label}\")\n",
    "print(\"Probabilités par classe :\")\n",
    "for name, p in zip(CLASS_NAMES, preds[0]):\n",
    "    print(f\"  {name}: {p*100:.2f} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70fa5054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Image: 00e00912-bf75-4cf8-8b7d-ad64b73bea5f___Mt.N.V_HL 6067_90deg.JPG - Pred: Healthy | Probas: ['0.0%', '0.0%', '100.0%', '0.0%']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Image: 00e00912-bf75-4cf8-8b7d-ad64b73bea5f___Mt.N.V_HL 6067_new30degFlipLR.JPG - Pred: Healthy | Probas: ['0.0%', '0.0%', '100.0%', '0.0%']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Image: 02f95acb-5d92-4f2a-b7ec-3af8709ee7c9___Mt.N.V_HL 9078_90deg.JPG - Pred: Healthy | Probas: ['0.2%', '0.5%', '99.2%', '0.1%']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Image: 03027791-26bb-4c46-960e-8df76e27042c___Mt.N.V_HL 6070_new30degFlipLR.JPG - Pred: Healthy | Probas: ['0.0%', '0.0%', '99.1%', '0.8%']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Image: 03492a0d-6ad7-42ec-a742-c2f1fa59499a___Mt.N.V_HL 6035_270deg.JPG - Pred: Healthy | Probas: ['0.0%', '0.1%', '99.9%', '0.0%']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Image: 03492a0d-6ad7-42ec-a742-c2f1fa59499a___Mt.N.V_HL 6035_new30degFlipLR.JPG - Pred: Healthy | Probas: ['0.0%', '0.0%', '99.9%', '0.1%']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Image: 05cff9d7-0f63-4b6e-9aa3-199cf9ffa64c___Mt.N.V_HL 9111_270deg.JPG - Pred: Healthy | Probas: ['0.2%', '0.7%', '98.0%', '1.0%']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Image: 05cff9d7-0f63-4b6e-9aa3-199cf9ffa64c___Mt.N.V_HL 9111_new30degFlipLR.JPG - Pred: Healthy | Probas: ['0.1%', '0.6%', '97.9%', '1.5%']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Image: 0708190e-d6a1-4186-8428-1cd816419bfd___Mt.N.V_HL 9017.JPG - Pred: Healthy | Probas: ['0.0%', '0.3%', '99.5%', '0.1%']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Image: 0708190e-d6a1-4186-8428-1cd816419bfd___Mt.N.V_HL 9017_180deg.JPG - Pred: Healthy | Probas: ['0.0%', '0.2%', '99.6%', '0.1%']\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "healthy_imgs = glob('./DL/Grapevine Disease Dataset Original Data/test/Healthy/*.jpg')\n",
    "for path in healthy_imgs[:10]:  # Prend 10 exemples\n",
    "    arr = prepare_image(path)\n",
    "    preds = model.predict(arr)\n",
    "    pred_idx = int(np.argmax(preds))\n",
    "    print(f\"Image: {os.path.basename(path)} - Pred: {CLASS_NAMES[pred_idx]} | Probas: {[f'{p*100:.1f}%' for p in preds[0]]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
